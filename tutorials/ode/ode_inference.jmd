# Ordinary differential equation model
Simon Frost (@sdwfrost), 2020-04-27

## Introduction

The classical ODE version of the SIR model is:

- Deterministic
- Continuous in time
- Continuous in state

## Libraries

```julia
using DifferentialEquations
using SimpleDiffEq
using DiffEqCallbacks
using Random
using Distributions
using DiffEqParamEstim
using DataFrames
using DataFrames
using StatsPlots
using BenchmarkTools
```

## Transitions

The following function provides the derivatives of the model, which it changes in-place. State variables and parameters are unpacked from `u` and `p`; this incurs a slight performance hit, but makes the equations much easier to read.

A variable is included for the number of infections, $Y$.

```julia
function sir_ode!(du,u,p,t)
    (S,I,R,Y) = u
    (β,c,γ) = p
    N = S+I+R
    infection = β*c*I/N*S
    recovery = γ*I
    @inbounds begin
        du[1] = -infection
        du[2] = infection - recovery
        du[3] = recovery
        du[4] = infection
    end
    nothing
end;
```

## Time domain

We set the timespan for simulations, `tspan`, initial conditions, `u0`, and parameter values, `p` (which are unpacked above as `[β,γ]`).

```julia
δt = 0.1
tmax = 40.0
tspan = (0.0,tmax)
t = 0.0:δt:tmax
obstimes = 0:1.0:tmax;
```

## Initial conditions

```julia
u0 = [990.0,10.0,0.0,0.0]; # S,I.R,Y
```

## Parameter values

```julia
p = [0.05,10.0,0.25]; # β,c,γ
```

## Accumulator interface

```julia
affect!(integrator) = integrator.u[4] = 0.0
cb_zero = PresetTimeCallback(obstimes,affect!)
```

## Running the model

```julia
prob_ode = ODEProblem(sir_ode!,u0,tspan,p)
```

```julia
sol_ode = solve(prob_ode,callback=cb_zero);
```
## Post-processing

We can convert the output to a dataframe for convenience.

```julia
df_ode = DataFrame(sol_ode(obstimes)')
df_ode[!,:t] = obstimes;
```

## Plotting

We can now plot the results.

```julia
@df df_ode plot(:t,
    [:x1 :x2 :x3 :x4],
    label=["S" "I" "R" "Y"],
    xlabel="Time",
    ylabel="Number")
```

## Generating data

```julia
data = rand.(Poisson.(df_ode[!,:x4]))
```

```julia
plot(obstimes,data)
plot!(obstimes,df_ode[!,:x4])
```

## Using Optim.jl directly

```julia
using Optim
```

### Single parameter optimization

Sum of squares for a single parameter model (β).

```julia
function ss1(β)
    prob = remake(prob_ode,u0=[990.0,10.0,0.0,0.0],p=[β,10.0,0.25])
    sol = solve(prob,Tsit5(),callback=cb_zero,saveat=obstimes)
    sol_data = sol(obstimes)[4,:]
    return(sum((sol_data - data) .^2))
end
```

Negative log-likelihood for a single parameter, β.

```julia
function nll1(β)
    prob = remake(prob_ode,u0=[990.0,10.0,0.0,0.0],p=[β,10.0,0.25])
    sol = solve(prob,Tsit5(),callback=cb_zero,saveat=obstimes)
    sol_data = sol(obstimes)[4,:]
    -sum(logpdf.(Poisson.(sol_data),data))
end
```

Bounds and initial values for optimization.

```julia
lower1 = 0.0
upper1 = 1.0
initial_x1 = 0.1
```

Model fit using sum of squares.

```julia
opt1_ss = optimize(ss1,lower1,upper1)
opt1_ss.minimizer
```

Model fit using (negative) log likelihood.

```julia
opt1_nll = optimize(nll1,lower1,upper1)
opt1_nll.minimizer
```

### Multiparameter optimization

Multiple parameters are handled in the cost function using an array argument. Firstly, sum of squares.

```julia
function ss2(x)
    (i0,β) = x
    I = i0*1000.0
    prob = remake(prob_ode,u0=[1000-I,I,0.0,0.0],p=[β,10.0,0.25])
    sol = solve(prob,Tsit5(),callback=cb_zero,saveat=obstimes)
    sol_data = sol(obstimes)[4,:]
    return(sum((sol_data - data) .^2))
end
```

Secondly, negative log-likelihood.

```julia
function nll2(x)
    (i0,β) = x
    I = i0*1000.0
    prob = remake(prob_ode,u0=[1000-I,I,0.0,0.0],p=[β,10.0,0.25])
    sol = solve(prob,Tsit5(),callback=cb_zero,saveat=obstimes)
    sol_data = sol(obstimes)[4,:]
    -sum(logpdf.(Poisson.(sol_data),data))
end
```

Two-parameter lower and upper bounds and initial conditions.

```julia
lower2 = [0.0,0.0]
upper2 = [1.0,1.0]
initial_x2 = [0.01,0.1]
```

```julia
opt2_ss = optimize(ss2,lower2,upper2,initial_x2)
opt2_ss.minimizer
```

```julia
opt2_nll = optimize(nll2,lower2,upper2,initial_x2)
opt2_nll.minimizer
```

## Using DiffEqParamEstim

```julia
function loss_function(sol)
    sol_data = DataFrame(sol(obstimes)')[!,:x4]
    -sum(logpdf.(Poisson.(sol_data),data))
end
```

```julia
prob_generator = (prob,q) -> remake(prob,
                            u0=[1000-(q[1]*1000),q[1]*1000,0.0,0.0],
                            p=[q[2],10.0,0.25])
```

```julia
cost_function = build_loss_objective(prob_ode,
    Tsit5(),
    loss_function,
    prob_generator = prob_generator,
    maxiters=10000,
    verbose=false,
    callback=cb_zero)
```

### Optim interface

```julia
opt_pe1 = Optim.optimize(cost_function,lower2,upper2,initial_x2)
opt_pe1.minimizer
```

### NLopt interface

```julia
using NLopt
opt = Opt(:LD_MMA, 2)
opt.lower_bounds = lower2
opt.upper_bounds = upper2
opt.min_objective = cost_function
(minf,minx,ret) = NLopt.optimize(opt,initial_x2)
```

### BlackBoxOptim interface

```julia
using BlackBoxOptim
bound1 = Tuple{Float64, Float64}[(0.0,1.0),(0.0, 1.0)]
result = bboptimize(cost_function;SearchRange = bound1, MaxSteps = 110e3)
```

```{julia; echo=false; skip="notebook"}
include(joinpath(@__DIR__,"tutorials","appendix.jl"))
appendix()
```
